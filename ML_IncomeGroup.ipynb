{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KWLee1999/kNN-LogReg-prediction/blob/main/ML_IncomeGroup.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n20F9EUbGMVi"
      },
      "source": [
        "Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ed434d87",
        "outputId": "0e0f0f56-9fc9-4596-9d8a-29ecf605e20a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting imbalanced-learn\n",
            "  Downloading imbalanced_learn-0.14.0-py3-none-any.whl.metadata (8.8 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.25.2 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy<2,>=1.11.4 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (1.16.1)\n",
            "Requirement already satisfied: scikit-learn<2,>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (1.6.1)\n",
            "Requirement already satisfied: joblib<2,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (3.6.0)\n",
            "Downloading imbalanced_learn-0.14.0-py3-none-any.whl (239 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.0/240.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: imbalanced-learn\n",
            "Successfully installed imbalanced-learn-0.14.0\n",
            "Collecting yellowbrick\n",
            "  Downloading yellowbrick-1.5-py3-none-any.whl.metadata (7.7 kB)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from yellowbrick) (3.10.0)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from yellowbrick) (1.16.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from yellowbrick) (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from yellowbrick) (2.0.2)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from yellowbrick) (0.12.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (1.3.3)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (2.9.0.post0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.0.0->yellowbrick) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.0.0->yellowbrick) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib!=3.0.0,>=2.0.2->yellowbrick) (1.17.0)\n",
            "Downloading yellowbrick-1.5-py3-none-any.whl (282 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m282.6/282.6 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: yellowbrick\n",
            "Successfully installed yellowbrick-1.5\n"
          ]
        }
      ],
      "source": [
        "!pip install imbalanced-learn\n",
        "!pip install yellowbrick"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iptANkhdIoi4",
        "outputId": "0a905313-c85a-4ff5-c43e-1fc081f9d63a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "# Import General library\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math as mt\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Import Data Processing library\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "\n",
        "# Import Learning Models library\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Import Evaluation Metriccs library\n",
        "from sklearn.metrics import classification_report, roc_curve, auc, precision_recall_curve, average_precision_score, accuracy_score\n",
        "from yellowbrick.classifier import ConfusionMatrix\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjIpwDiDGaP2"
      },
      "source": [
        "Define basic functions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "j3FyAET09fCf"
      },
      "outputs": [],
      "source": [
        "def exp_data_analysis(df, cols_format, unique_classes):\n",
        "    for label in df.columns[:-1]:\n",
        "        if cols_format[label] in ['binary','cont']:\n",
        "            for val in unique_classes:\n",
        "                plt.hist(df[df[\"Income-Class\"]==val][label],label=val,alpha=0.7)\n",
        "            plt.ylabel(\"No of Adults\")\n",
        "            plt.xlabel(label)\n",
        "            plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "\n",
        "        if cols_format[label] not in ['binary','cont']:\n",
        "           df[label].value_counts().plot(kind=\"bar\", figsize=(10,5))\n",
        "           plt.title(f\"{str(label)} distribution\")\n",
        "           plt.xlabel(label)\n",
        "           plt.ylabel(\"Count\")\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "def one_hot_encoder(df, df_ohe, col_names):\n",
        "    encoder = OneHotEncoder()\n",
        "    encoded = encoder.fit_transform(df_ohe)\n",
        "\n",
        "    encoded_df = pd.DataFrame(\n",
        "    encoded.toarray(),\n",
        "    columns=encoder.get_feature_names_out(col_names)\n",
        "    )\n",
        "\n",
        "    df_combined = pd.concat([df,encoded_df],axis=1)\n",
        "\n",
        "    return df_combined\n",
        "\n",
        "def confusion_matrix(model, unique_classes, X_train, y_train, X_test, y_test):\n",
        "    cm = ConfusionMatrix(model, classes=unique_classes)\n",
        "    cm.fit(X_train, y_train)\n",
        "    cm.score(X_test, y_test)\n",
        "\n",
        "    cm.poof()\n",
        "\n",
        "def class_to_int(y_set):\n",
        "    int_y_test = y_set.copy()\n",
        "    int_y_test[int_y_test == ' <=50K'] = '0'\n",
        "    int_y_test[int_y_test == ' >50K'] = '1'\n",
        "    int_y_test = int_y_test.astype('int32')\n",
        "\n",
        "    return int_y_test\n",
        "\n",
        "def roc_auc_graph(model, unique_classes, X_test, y_test,k,distance):\n",
        "    fpr = dict()\n",
        "    tpr = dict()\n",
        "    roc_auc = dict()\n",
        "    n_classes = len(unique_classes)\n",
        "\n",
        "    roc_y_test = class_to_int(y_test)\n",
        "\n",
        "    for i in range(n_classes):\n",
        "        fpr[i], tpr[i], _ = roc_curve((roc_y_test == i).astype(int), model.predict_proba(X_test)[:, i])\n",
        "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "\n",
        "    # Plot ROC curves\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    colors = ['blue', 'red']\n",
        "    for i, color in enumerate(colors):\n",
        "        tempclass = \" <=50K\" if i == 0 else \"> 50K\"\n",
        "        plt.plot(fpr[i], tpr[i], color=color, lw=2, label=f'ROC curve (class {tempclass}) (area = {roc_auc[i]:.4f})')\n",
        "        if k != \"\":\n",
        "          plt.annotate(f'K={k}', xy=(0.8, 0.2), xytext=(0.8, 0.2))\n",
        "          plt.annotate(f'{distance}', xy=(0.8, 0.16), xytext=(0.8, 0.16))\n",
        "\n",
        "    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "\n",
        "    # Display AUC values\n",
        "    for i in range(n_classes):\n",
        "        print(f\"AUC for class {i}: {roc_auc[i]:.4f}\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "def scale_dataset(dataframe, oversample=False):\n",
        "  # Extract features from the dataframe: all columns except the last one\n",
        "  X = dataframe[dataframe.columns[:-1]].values\n",
        "  # Extract target variable from the dataframe: the last column\n",
        "  y = dataframe[dataframe.columns[-1]].values\n",
        "  # Initialize a standard scaler object\n",
        "  scaler = StandardScaler()\n",
        "  # Fit the scaler to the data and transform the features to have mean=0 and std deviation=1\n",
        "  X = scaler.fit_transform(X)\n",
        "\n",
        "  # Check if oversampling is required\n",
        "  if oversample:\n",
        "      # Initialize a random oversampler object for handling class imbalance\n",
        "      ros = RandomOverSampler()\n",
        "      # Use the oversampler to balance class distribution by duplicating some minority class samples\n",
        "      X, y = ros.fit_resample(X, y)\n",
        "\n",
        "  # Combine the standardized (and optionally oversampled) features and target into one array\n",
        "  data = np.hstack((X, np.reshape(y, (-1, 1))))\n",
        "\n",
        "  # Return the combined data, the features, and the target variable\n",
        "  return data, X, y\n",
        "\n",
        "def model(x):\n",
        "      return 1 / (1 + np.exp(-x))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGo81bDRGkbM"
      },
      "source": [
        "Get the data ready for processing:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "id": "BKtAOhV4iuxr",
        "outputId": "ed7a4f57-c054-4d58-c8e9-9808769d3594"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2274757204.py:23: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  ds['Income_Class'] = ds['Income_Class'].replace({\"<=50K.\": 0, \">50K.\": 1,\"<=50K\": 0, \">50K\": 1})\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   age  fnlwgt  education_num  capital_gain  capital_loss  hours_per_week  \\\n",
              "0   39   77516             13          2174             0              40   \n",
              "1   50   83311             13             0             0              13   \n",
              "2   38  215646              9             0             0              40   \n",
              "3   53  234721              7             0             0              40   \n",
              "4   28  338409             13             0             0              40   \n",
              "\n",
              "   workclass_?  workclass_Federal_gov  workclass_Local_gov  \\\n",
              "0          0.0                    0.0                  0.0   \n",
              "1          0.0                    0.0                  0.0   \n",
              "2          0.0                    0.0                  0.0   \n",
              "3          0.0                    0.0                  0.0   \n",
              "4          0.0                    0.0                  0.0   \n",
              "\n",
              "   workclass_Never_worked  ...  relationship_Other_relative  \\\n",
              "0                     0.0  ...                          0.0   \n",
              "1                     0.0  ...                          0.0   \n",
              "2                     0.0  ...                          0.0   \n",
              "3                     0.0  ...                          0.0   \n",
              "4                     0.0  ...                          0.0   \n",
              "\n",
              "   relationship_Own_child  relationship_Unmarried  relationship_Wife  \\\n",
              "0                     0.0                     0.0                0.0   \n",
              "1                     0.0                     0.0                0.0   \n",
              "2                     0.0                     0.0                0.0   \n",
              "3                     0.0                     0.0                0.0   \n",
              "4                     0.0                     0.0                1.0   \n",
              "\n",
              "   race_Amer_Indian_Eskimo  race_Asian_Pac_Islander  race_Black  race_Other  \\\n",
              "0                      0.0                      0.0         0.0         0.0   \n",
              "1                      0.0                      0.0         0.0         0.0   \n",
              "2                      0.0                      0.0         0.0         0.0   \n",
              "3                      0.0                      0.0         1.0         0.0   \n",
              "4                      0.0                      0.0         1.0         0.0   \n",
              "\n",
              "   race_White  Income_Class  \n",
              "0         1.0             0  \n",
              "1         1.0             0  \n",
              "2         1.0             0  \n",
              "3         0.0             0  \n",
              "4         0.0             0  \n",
              "\n",
              "[5 rows x 49 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e3cf578a-df0d-40dd-b6be-7bb3ac9842d6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>fnlwgt</th>\n",
              "      <th>education_num</th>\n",
              "      <th>capital_gain</th>\n",
              "      <th>capital_loss</th>\n",
              "      <th>hours_per_week</th>\n",
              "      <th>workclass_?</th>\n",
              "      <th>workclass_Federal_gov</th>\n",
              "      <th>workclass_Local_gov</th>\n",
              "      <th>workclass_Never_worked</th>\n",
              "      <th>...</th>\n",
              "      <th>relationship_Other_relative</th>\n",
              "      <th>relationship_Own_child</th>\n",
              "      <th>relationship_Unmarried</th>\n",
              "      <th>relationship_Wife</th>\n",
              "      <th>race_Amer_Indian_Eskimo</th>\n",
              "      <th>race_Asian_Pac_Islander</th>\n",
              "      <th>race_Black</th>\n",
              "      <th>race_Other</th>\n",
              "      <th>race_White</th>\n",
              "      <th>Income_Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>39</td>\n",
              "      <td>77516</td>\n",
              "      <td>13</td>\n",
              "      <td>2174</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>50</td>\n",
              "      <td>83311</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>38</td>\n",
              "      <td>215646</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>53</td>\n",
              "      <td>234721</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>28</td>\n",
              "      <td>338409</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 49 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e3cf578a-df0d-40dd-b6be-7bb3ac9842d6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e3cf578a-df0d-40dd-b6be-7bb3ac9842d6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e3cf578a-df0d-40dd-b6be-7bb3ac9842d6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-11967ae1-e804-460e-96c8-13f69e41059e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-11967ae1-e804-460e-96c8-13f69e41059e')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-11967ae1-e804-460e-96c8-13f69e41059e button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "ds"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "filename = '/content/drive/MyDrive/adult.data' # update the path to the file\n",
        "cols = ['age','workclass','fnlwgt','education','education-num','marital-status','occupation','relationship','race','sex','capital-gain','capital-loss','hours-per-week','native-country','Income-Class']\n",
        "\n",
        "df = pd.read_csv(filename, names=cols) # add the column name to the dataframe (panda)\n",
        "\n",
        "df = df.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
        "\n",
        "df.head()\n",
        "\n",
        "#exp_data_analysis(df, cols_format, unique_classes)\n",
        "\n",
        "col_names = ['workclass','marital-status','occupation','relationship','race']\n",
        "df_ohe = df[['workclass','marital-status','occupation','relationship','race']]\n",
        "\n",
        "ds = one_hot_encoder(df, df_ohe, col_names)\n",
        "ds.columns = ds.columns.str.replace('-','_')\n",
        "\n",
        "cols = [col for col in ds.columns if col != 'Income_Class'] + ['Income_Class']\n",
        "ds = ds[cols]\n",
        "\n",
        "#Data Processing\n",
        "#1. Data quality issue. Remove the \".\" from Income Class.\n",
        "ds['Income_Class'] = ds['Income_Class'].replace({\"<=50K.\": 0, \">50K.\": 1,\"<=50K\": 0, \">50K\": 1})\n",
        "\n",
        "#2. Turn the sex into binary field\n",
        "ds['sex'] = ds['sex'].replace({\" Male\": 0, \" Female\": 1})\n",
        "\n",
        "#3. Drop the catagorical field that cannot be converted into binary and perform a proper labeling\n",
        "ds = ds.select_dtypes(exclude='object')\n",
        "\n",
        "unique_classes = ds['Income_Class'].unique()\n",
        "\n",
        "ds.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcxIJdbPGsJX"
      },
      "source": [
        "Split the data into Training, validating and testing sets.\n",
        "\n",
        "Over-sampling using SMOTE method:\n",
        "It works by interpolating between an existing minority class sample and some of its nearest neighbors to create new, synthetic data points."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19abcbb0",
        "outputId": "09c86dd5-293b-4d97-f32c-e1041e75223e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of training data before SMOTE: (39073, 48)\n",
            "Shape of training data after SMOTE: (59482, 48)\n",
            "Class distribution before SMOTE: 0    29741\n",
            "1     9332\n",
            "Name: count, dtype: int64\n",
            "Class distribution after SMOTE: 0    29741\n",
            "1    29741\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "sqrt_n = mt.floor(mt.sqrt(len(ds))) - 0 if mt.sqrt(len(ds))%2 > 0 else 1\n",
        "\n",
        "# Split the dataset using ratio according to rule of thumb\n",
        "# Split the data into training (80%) and the combined validation and test set\n",
        "train, temp = train_test_split(ds, train_size=0.8, random_state=42)\n",
        "# Split the combined validation (10%) and test set (10%)\n",
        "valid, test = train_test_split(temp, test_size=0.5, random_state=42)\n",
        "\n",
        "#Do scaling for the train data only\n",
        "train, X_train, y_train = scale_dataset(train, oversample=False)\n",
        "valid, X_valid, y_valid = scale_dataset(valid, oversample=False)\n",
        "test, X_test, y_test = scale_dataset(test, oversample=False)\n",
        "\n",
        "# Assuming X_train and y_train are your training features and labels\n",
        "# Initialize SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "\n",
        "# Apply SMOTE to the training data\n",
        "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "print(\"Shape of training data before SMOTE:\", X_train.shape)\n",
        "print(\"Shape of training data after SMOTE:\", X_train_smote.shape)\n",
        "print(\"Class distribution before SMOTE:\", pd.Series(y_train).value_counts())\n",
        "print(\"Class distribution after SMOTE:\", pd.Series(y_train_smote).value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AirJM3Zp7v7A"
      },
      "outputs": [],
      "source": [
        "def knn_model(X_train, y_train, X_valid, y_valid, X_test, y_test, sqrt_n, k_values, distances):\n",
        "\n",
        "  for i, k in enumerate(k_values, 1): # return k in: [(1, 1), (2, 5), (3, 20)] #Highest AUC\n",
        "\n",
        "      for distance in distances:\n",
        "        # Create a KNN classifier with the current k value\n",
        "        knn = KNeighborsClassifier(n_neighbors=k,metric=distance, p=3) # Help to test manhattan / euclidean\n",
        "        print(\"----------------------------------K=\"f\"{k} ------------------------------------------\")\n",
        "        print(f'****************{distance}***********************')\n",
        "        knn.fit(X_train, y_train)\n",
        "\n",
        "        # Valiadation data\n",
        "        cv_scores = cross_val_score(knn, X_train, y_train, cv=5)\n",
        "\n",
        "        # Evaluate the model on the validation set\n",
        "        # Calculate and display the accuracy on the test set\n",
        "        y_valid_pred = knn.predict(X_valid)\n",
        "        valid_accuracy = accuracy_score(y_valid, y_valid_pred)\n",
        "        print(f\"Validation Set Accuracy:{valid_accuracy:.2f}\")\n",
        "\n",
        "        # Evaluate the model on the test set\n",
        "        # Calculate and display the accuracy on the test set\n",
        "        y_test_pred = knn.predict(X_test)\n",
        "        test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "        print(f\"Test Set Accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "        # Print cross-validation scores\n",
        "        print(\"Cross-Validation Scores:\", cv_scores)\n",
        "        print(f\"Mean Cross-Validation Accuracy: {cv_scores.mean():.4f}\" )\n",
        "\n",
        "        # Classification Report for Validation Set\n",
        "        print(\"Classification Report for Validation Set:\")\n",
        "        print(classification_report(y_valid, y_valid_pred))\n",
        "\n",
        "        # Classification Report for Test Set\n",
        "        print(\"Classification Report for Test Set:\")\n",
        "        print(classification_report(y_test, y_test_pred))\n",
        "\n",
        "        #Confusion Matrix\n",
        "        #==========================================================================\n",
        "        print(f'****************Cufusion matrix of {k} for Validation Set***********************')\n",
        "        confusion_matrix(knn,unique_classes,X_train, y_train,X_test, y_test)\n",
        "\n",
        "        #Compute ROC curve and ROC area for each class\n",
        "        #==========================================================================\n",
        "        print(f'****************AUC of {k} for Validation Set***********************')\n",
        "        roc_auc_graph(knn,unique_classes, X_valid, y_valid,k,distance)\n",
        "\n",
        "        #Compute ROC curve and ROC area for each class\n",
        "        #==========================================================================\n",
        "        print(f'****************AUC of {k} for Testing Set***********************')\n",
        "        roc_auc_graph(knn,unique_classes, X_test, y_test,k,distance)\n",
        "\n",
        "def logreg_model(X_train, y_train, X_valid, y_valid, X_test, y_test):\n",
        "    # instantiate the model\n",
        "    logreg = LogisticRegression(solver='liblinear', random_state=0)\n",
        "\n",
        "    # fit the model\n",
        "    logreg.fit(X_train, y_train)\n",
        "\n",
        "    cv_scores = cross_val_score(logreg, X_train, y_train, cv=5)\n",
        "\n",
        "    y_test_pred = logreg.predict(X_test)\n",
        "\n",
        "    # Print cross-validation scores\n",
        "    print(\"Cross-Validation Scores:\", cv_scores)\n",
        "    print(f\"Mean Cross-Validation Accuracy: {cv_scores.mean():.4f}\" )\n",
        "\n",
        "    y_valid_pred = logreg.predict(X_valid)\n",
        "    valid_accuracy = accuracy_score(y_valid, y_valid_pred)\n",
        "\n",
        "    print(f\"Validation Set Accuracy:{valid_accuracy:.2f}\")\n",
        "\n",
        "    # Classification Report for Validation Set\n",
        "    print(\"Classification Report for Validation Set:\")\n",
        "    print(classification_report(y_valid, y_valid_pred))\n",
        "\n",
        "    print('Model accuracy score: {0:0.4f}'. format(accuracy_score(y_test, y_test_pred)))\n",
        "\n",
        "    # Classification Report for Test Set\n",
        "    print(\"Classification Report for Test Set:\")\n",
        "    print(classification_report(y_test, y_test_pred))\n",
        "\n",
        "    #Confusion Matrix\n",
        "    #==========================================================================\n",
        "    print(f'****************Cufusion matrix of Logistic Regression for Validation Set***********************')\n",
        "    confusion_matrix(logreg, unique_classes, X_train, y_train, X_test, y_test)\n",
        "\n",
        "    #Compute ROC curve and ROC area for each class\n",
        "    #==========================================================================\n",
        "    print(f'****************AUC of Logistic Regression for Validation Set***********************')\n",
        "    roc_auc_graph(logreg, unique_classes, X_valid, y_valid,\"\",\"\")\n",
        "\n",
        "    #Compute ROC curve and ROC area for each class\n",
        "    #==========================================================================\n",
        "    print(f'****************AUC of Logistic Regression for Testing Set***********************')\n",
        "    roc_auc_graph(logreg, unique_classes, X_test, y_test,\"\",\"\")\n",
        "\n",
        "def svm_model(X_train, y_train, X_valid, y_valid, X_test, y_test, krn, reg, gmma):\n",
        "    scaler = StandardScaler()\n",
        "\n",
        "    # Fit the scaler on training data and transform it.\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "\n",
        "    # Transform the test data using the same scaler. It's important not to fit again to avoid data leakage.\n",
        "    X_test = scaler.transform(X_test)\n",
        "\n",
        "    # SVM Classifier: Support Vector Machine with a linear kernel.\n",
        "    svm_model = SVC(kernel=krn, C=reg, gamma = gmma)\n",
        "    svm_model.fit(X_train, y_train)\n",
        "    svm_predictions = svm_model.predict(X_test)\n",
        "\n",
        "    # Calculate the accuracy of the SVM model's predictions.\n",
        "    svm_accuracy = accuracy_score(y_test, svm_predictions)\n",
        "\n",
        "    # Generate a detailed classification report showing performance metrics for the SVM.\n",
        "    svm_classification_report = classification_report(y_test, svm_predictions)\n",
        "\n",
        "    # Display the SVM's accuracy ,classification report and confusion matrix.\n",
        "    print(\"SVM Accuracy:\", svm_accuracy)\n",
        "    print(\"SVM Classification Report:\\n\", svm_classification_report)\n",
        "    confusion_matrix(svm_model, unique_classes, X_train, y_train, X_test, y_test)\n",
        "\n",
        "def rf_model(X_train, y_train, X_valid, y_valid, X_test, y_test, n_est, rd_state, min_leaf):\n",
        "    scaler = StandardScaler()\n",
        "\n",
        "    # Fit the scaler on training data and transform it.\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "\n",
        "    # Transform the test data using the same scaler. It's important not to fit again to avoid data leakage.\n",
        "    X_test = scaler.transform(X_test)\n",
        "\n",
        "    # Random Forest Classifier: An ensemble of decision trees.\n",
        "    rf_model = RandomForestClassifier(n_estimators=n_est, criterion='entropy', random_state=rd_state, max_depth = None)\n",
        "    rf_model.fit(X_train, y_train)\n",
        "    rf_predictions = rf_model.predict(X_test)\n",
        "\n",
        "    # Calculate the accuracy of the Random Forest model's predictions.\n",
        "    rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
        "\n",
        "    # Generate a detailed classification report showing performance metrics for the Random Forest.\n",
        "    rf_classification_report = classification_report(y_test, rf_predictions)\n",
        "\n",
        "    # Display the Random Forest's accuracy, classification report and confusion matrix.\n",
        "    print(\"Random Forest Accuracy:\", rf_accuracy)\n",
        "    print(\"Random Forest Classification Report:\\n\", rf_classification_report)\n",
        "    confusion_matrix(rf_model, unique_classes, X_train, y_train, X_test, y_test)\n",
        "\n",
        "logreg_model(X_train_smote, y_train_smote, X_valid, y_valid, X_test, y_test)\n",
        "knn_model(X_train_smote, y_train_smote, X_valid, y_valid, X_test, y_test, k_values = [221], distinces = [\"euclidean\",\"manhattan\",\"minkowski\"])\n",
        "rf_model(X_train_smote, y_train_smote, X_valid, y_valid, X_test, y_test, n_est = 500, rd_state = 42, min_leaf =10)\n",
        "svm_model(X_train_smote, y_train_smote, X_valid, y_valid, X_test, y_test, krn = 'poly', reg = 0.1, gmma = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7f8efae3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "92f2562f-abed-4f22-d69b-b04dc1fafd00"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X_train_smote' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1366313793.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Fit GridSearchCV to the oversampled training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_smote\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_smote\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Print the best parameters and the corresponding best score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train_smote' is not defined"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [10, 50, 100, 200, 500, 1000, 10000],\n",
        "    'random_state': [42],\n",
        "    'min_samples_leaf': [5, 10, 15]\n",
        "}\n",
        "\n",
        "# Initialize the Random Forest Classifier\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, scoring='f1', n_jobs=-1)\n",
        "\n",
        "# Fit GridSearchCV to the oversampled training data\n",
        "grid_search.fit(X_train_smote, y_train_smote)\n",
        "\n",
        "# Print the best parameters and the corresponding best score\n",
        "print(\"Best parameters found: \", grid_search.best_params_)\n",
        "print(\"Best F1 score found: \", grid_search.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0c026a48"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Define the parameter grid for SVM\n",
        "param_grid_svm = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
        "    'gamma': [1, 0.1, 0.01, 0.001],     # Kernel coefficient\n",
        "}\n",
        "\n",
        "# Initialize the SVM Classifier\n",
        "svm = SVC()\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_search_svm = GridSearchCV(estimator=svm, param_grid=param_grid_svm, cv=3, scoring='f1', n_jobs=-1)\n",
        "\n",
        "# Fit GridSearchCV to the oversampled training data\n",
        "grid_search_svm.fit(X_train_smote, y_train_smote)\n",
        "\n",
        "# Print the best parameters and the corresponding best score\n",
        "print(\"Best parameters found for SVM: \", grid_search_svm.best_params_)\n",
        "print(\"Best F1 score found for SVM: \", grid_search_svm.best_score_)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}